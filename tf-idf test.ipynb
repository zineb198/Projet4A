{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import numpy as np\n",
    "import collections as col\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import lil_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(\"./arxiv_articles.csv\", sep=\"|\",usecols=[1,3,4],nrows=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "#fonctions appliquées sur chaque document pour nettoyage\n",
    "b = lambda new : \" \".join([ps.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \" ,new.lower()).split() if i not in stop_words]).split()\n",
    "#a = lambda x : col.Counter(re.findall('\\w+',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['cleaned']=data_test['summary'].apply(b)\n",
    "#data_test['dict']=data_test['cleaned'].apply(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcul_tf(d):\n",
    "    term_counts = pd.Series(d).value_counts()\n",
    "    max_mot = max(term_counts)\n",
    "    return 0.5 + 0.5 * (term_counts / max_mot)\n",
    "def compute_idf(D):\n",
    "    N = len(D)\n",
    "    all_terms = pd.concat(D)\n",
    "    nt = all_terms.index.value_counts() # The number of documents containing the term \"t\"\n",
    "    return np.log(N / nt)\n",
    "def compute_tf_idf_document(tf_document, idf):\n",
    "    return tf_document * np.array([idf[i] for i in tf_document.index])\n",
    "#calcul le tf idf pour 1 document\n",
    "def compute_tf_idf_corpus(D):\n",
    "    term_freq = [calcul_tf(d) for d in D]\n",
    "    idf = compute_idf(term_freq)\n",
    "    return [compute_tf_idf_document(d, idf) for d in term_freq]\n",
    "#prend en entree une colonne panda series et return un "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'toappend'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-3c23a70a8f56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#array de nos mots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mall_mot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_idf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;31m#attention il n'additionne pas si deux fois le même mot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_idf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'toappend'"
     ]
    }
   ],
   "source": [
    "tf_idf = compute_tf_idf_corpus(data_test.loc[:5, \"cleaned\"])\n",
    "#liste avec comme indice le numéro du document et pour chaque document un panda series \n",
    "#avec mot comme index et tf_idf pour le mot comme values\n",
    "#array de nos mots\n",
    "all_mot = pd.concat(tf_idf).index #attention il n'additionne pas si deux fois le même mot\n",
    "print((tf_idf.append(self=tf_idf,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92,)\n"
     ]
    }
   ],
   "source": [
    "for i in len(all_mot):\n",
    "    if data.loc[:5, all_mot[i]].notnull() in  \n",
    "    mat[:,i]="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-120-eff3d2bdcf32>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-120-eff3d2bdcf32>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    c = lambda x : x if x not 'NaN'\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "data=pd.DataFrame(tf_idf)\n",
    "print(data.loc[:5, 'group'])\n",
    "c = lambda x : x if x not 'NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = compute_idf(term_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
